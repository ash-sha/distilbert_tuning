{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "915234aa-2e83-4430-bd4c-06edcdb19bc9",
   "metadata": {},
   "source": [
    "# Uploading and Sharing Models on Hugging Face Hub with Intel Optimizations\n",
    "\n",
    "<img src=\"https://media.licdn.com/dms/image/D4D12AQETAuI3Jb8DHg/article-cover_image-shrink_720_1280/0/1688135186433?e=2147483647&v=beta&t=TE7Ew2JTFECpXUHFLyDtBdRsBgoONGV4roThKcoHdeA\" alt=\"Alt Text\" style=\"width: 400px;\"/>\n",
    "\n",
    "\n",
    "Here, we'll learn how to take a model trained using Hugging Face APIs with the Intel Extension for PyTorch and upload it to the Hugging Face Hub. \n",
    "\n",
    "## Why This is Important\n",
    "\n",
    "Sharing models on platforms like Hugging Face Hub not only contributes to the open-source community but also allows for wider testing, evaluation, and improvement of models by others. This process is critical for collaborative development and advancing the field of AI.\n",
    "\n",
    "### Key Learning Points\n",
    "\n",
    "- **Model Upload**: We will go through the steps of uploading our trained model to the Hugging Face Hub.\n",
    "- **Creating a Model Card**: A model card is crucial for documenting our model. It provides information about the model's purpose, architecture, and training data, guiding other users in understanding and using the model effectively.\n",
    "- **Open Sourcing the Model**: By open-sourcing our model, we contribute to the community and enable collective advancements in AI and NLP.\n",
    "- **Evaluation on Hugging Face Hub**: We'll also look at how our model can be evaluated directly on the Hugging Face Hub.\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "- A Hugging Face account and a token with write permissions are necessary to upload models to the Hub.\n",
    "\n",
    "Let's start by setting up our environment and preparing our model for upload to the Hugging Face Hub.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc69d348-ba24-4ec5-ac59-3cfe5a3726cd",
   "metadata": {},
   "source": [
    "### Logging in to Hugging Face\n",
    "\n",
    "Before uploading the model, you need to authenticate with Hugging Face. Ensure you have an account and are logged in. The `notebook_login` function provides an easy way to log in for notebook environments.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "3d4a3f02-32da-46b5-aebb-f2fb5e81e1de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T09:01:02.377808Z",
     "start_time": "2024-11-23T09:01:02.148550Z"
    }
   },
   "source": [
    "from huggingface_hub import notebook_login, Repository\n",
    "\n",
    "# Login to Hugging Face\n",
    "notebook_login()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a3e4b94ba2e242fe90f4eeb899f2d7a7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "10831457-cded-48fb-a3a7-e6f4a842b900",
   "metadata": {},
   "source": [
    "#### Model and Tokenizer Loading\n",
    "\n",
    "In this cell, we load our trained model and tokenizer:\n",
    "- We use `AutoModelForSequenceClassification` and `AutoTokenizer` to load the model and tokenizer. The model is loaded from a saved checkpoint, while the tokenizer is loaded using the base DistilBERT tokenizer.\n",
    "- `checkpoint_path` should be set to the path where your model checkpoint is saved. Always target the last checkpoint if the model was trained succesfully."
   ]
  },
  {
   "cell_type": "code",
   "id": "f7d7afd2-3e03-4e74-8674-b5e0426680b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T09:01:05.416078Z",
     "start_time": "2024-11-23T09:01:02.385801Z"
    }
   },
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "# Define the path to the checkpoint\n",
    "checkpoint_path = r\"./results/checkpoint-1000\"  # Replace with your checkpoint folder\n",
    "\n",
    "# Load the model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint_path)\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aswathshakthi/PycharmProjects/MLOps/madewithml/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "62dd0d4d-03e3-432e-9e65-ddcc6c8637ac",
   "metadata": {},
   "source": [
    "#### Saving and Uploading the Model and Tokenizer\n",
    "\n",
    "Here, we prepare and upload the model and tokenizer to the Hugging Face Hub:\n",
    "- The model and tokenizer are saved locally with the names specified in `model_name_on_hub`.\n",
    "- `push_to_hub` methods are used to upload both the model and tokenizer to the Hugging Face Hub under your username."
   ]
  },
  {
   "cell_type": "code",
   "id": "f4c59a28-8158-42c6-97f1-2723919d82ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T09:01:08.577113Z",
     "start_time": "2024-11-23T09:01:05.427377Z"
    }
   },
   "source": [
    "# Save the model and tokenizer\n",
    "model_name_on_hub = \"distilbert-emotions-clf-m1\"\n",
    "model.save_pretrained(model_name_on_hub)\n",
    "tokenizer.save_pretrained(model_name_on_hub)\n",
    "\n",
    "# Push to the hub\n",
    "model.push_to_hub(model_name_on_hub)\n",
    "tokenizer.push_to_hub(model_name_on_hub)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n",
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/aswathshakthi/distilbert-emotions-clf-m1/commit/087ddc8a47befb057beeaae24a77117dd8afa7ae', commit_message='Upload tokenizer', commit_description='', oid='087ddc8a47befb057beeaae24a77117dd8afa7ae', pr_url=None, repo_url=RepoUrl('https://huggingface.co/aswathshakthi/distilbert-emotions-clf-m1', endpoint='https://huggingface.co', repo_type='model', repo_id='aswathshakthi/distilbert-emotions-clf-m1'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "3b3b157a-2b48-44a5-8fd4-0a8de8f812b9",
   "metadata": {},
   "source": [
    "#### Model Uploaded to Hugging Face Model Hub\n",
    "\n",
    "Congratulations! Your fine-tuned model is now uploaded to the Hugging Face Model Hub. You can view and share your model using its URL: `https://huggingface.co/your-username/your-model-name`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cace9d1-1c22-4e8b-9210-08899c121ca3",
   "metadata": {},
   "source": [
    "## Creating and Uploading the Model Card\n",
    "\n",
    "A model card is a critical document that provides information about the model's purpose, creation, and usage. It enhances transparency and helps users understand and use the model appropriately. Here is a template below\n",
    "\n",
    "Check out this example model card: https://huggingface.co/eduardo-alvarez/distilbert-emotions-clf/blob/main/README.md"
   ]
  },
  {
   "cell_type": "code",
   "id": "7660c612-5fea-43b9-b34c-6126e95db32a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T09:01:08.588808Z",
     "start_time": "2024-11-23T09:01:08.585955Z"
    }
   },
   "source": [
    "model_card_content = \"\"\"\n",
    "# Model Card for My Fine-Tuned Model\n",
    "\n",
    "## Model Description\n",
    "- **Purpose**: [Describe the purpose of your model. What task does it perform?]\n",
    "- **Model architecture**: [Specify the architecture, e.g., BERT, GPT-2, etc.]\n",
    "- **Training data**: [Briefly describe the dataset used for training. Include any data cleaning or preprocessing steps.]\n",
    "\n",
    "## Intended Use\n",
    "- **Intended users**: [Who are the intended users of the model?]\n",
    "- **Use cases**: [Describe potential use cases for the model.]\n",
    "\n",
    "## Limitations\n",
    "- **Known limitations**: [Mention any known limitations of the model.]\n",
    "\n",
    "## Hardware \n",
    "- **Training Platform**: [Describe details about the systems and platform used to train the model.]\n",
    "\n",
    "## Software Optimizations\n",
    "- **Known Optimizations**: [Describe details about any optimizations used during training.]\n",
    "\n",
    "## Ethical Considerations\n",
    "- **Ethical concerns**: [Discuss any ethical concerns related to the use of your model.]\n",
    "\n",
    "## More Information\n",
    "- [Include any additional information, links, or references.]\n",
    "\n",
    "\"\"\""
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "8e9fde36-7c64-47e4-9a9f-02a1879e17a1",
   "metadata": {},
   "source": [
    "If you have git-lfs installed, you can try uploading directly. Git-LFS is not available in the Intel® Tiber™ AI Cloud free notebook environments at the time of creating this tutorial (1/30/24)"
   ]
  },
  {
   "cell_type": "code",
   "id": "6f65be83-978f-448f-b0de-3c0fcb1109e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T09:02:41.751053Z",
     "start_time": "2024-11-23T09:02:41.458555Z"
    }
   },
   "source": [
    "# Write the model card content to a file\n",
    "model_card_filename = f\"{model_name_on_hub}/README.md\"\n",
    "with open(model_card_filename, \"w\") as file:\n",
    "    file.write(model_card_content)\n",
    "\n",
    "# Push the model card to the hub\n",
    "repo = Repository(model_name_on_hub, clone_from=model_name_on_hub)\n",
    "repo.push_to_hub(commit_message=\"Add model card\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aswathshakthi/PycharmProjects/MLOps/madewithml/venv/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'Repository' (from 'huggingface_hub.repository') is deprecated and will be removed from version '1.0'. Please prefer the http-based alternatives instead. Given its large adoption in legacy code, the complete removal is only planned on next major release.\n",
      "For more details, please read https://huggingface.co/docs/huggingface_hub/concepts/git_vs_http.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Tried to clone a repository in a non-empty folder that isn't a git repository ('/Users/aswathshakthi/PycharmProjects/certified-developer/MLOps_Professional/lab9/distilbert_tuning/distilbert-emotions-clf-m1'). If you really want to do this, do it manually:\n cd /Users/aswathshakthi/PycharmProjects/certified-developer/MLOps_Professional/lab9/distilbert_tuning/distilbert-emotions-clf-m1 && git init && git remote add origin && git pull origin main\n or clone repo to a new folder and move your existing files there afterwards.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 7\u001B[0m\n\u001B[1;32m      4\u001B[0m     file\u001B[38;5;241m.\u001B[39mwrite(model_card_content)\n\u001B[1;32m      6\u001B[0m \u001B[38;5;66;03m# Push the model card to the hub\u001B[39;00m\n\u001B[0;32m----> 7\u001B[0m repo \u001B[38;5;241m=\u001B[39m \u001B[43mRepository\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_name_on_hub\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mclone_from\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel_name_on_hub\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      8\u001B[0m repo\u001B[38;5;241m.\u001B[39mpush_to_hub(commit_message\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAdd model card\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/PycharmProjects/MLOps/madewithml/venv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:114\u001B[0m, in \u001B[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    111\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m check_use_auth_token:\n\u001B[1;32m    112\u001B[0m     kwargs \u001B[38;5;241m=\u001B[39m smoothly_deprecate_use_auth_token(fn_name\u001B[38;5;241m=\u001B[39mfn\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m, has_token\u001B[38;5;241m=\u001B[39mhas_token, kwargs\u001B[38;5;241m=\u001B[39mkwargs)\n\u001B[0;32m--> 114\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/MLOps/madewithml/venv/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:132\u001B[0m, in \u001B[0;36m_deprecate_method.<locals>._inner_deprecate_method.<locals>.inner_f\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    130\u001B[0m     warning_message \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m message\n\u001B[1;32m    131\u001B[0m warnings\u001B[38;5;241m.\u001B[39mwarn(warning_message, \u001B[38;5;167;01mFutureWarning\u001B[39;00m)\n\u001B[0;32m--> 132\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/MLOps/madewithml/venv/lib/python3.10/site-packages/huggingface_hub/repository.py:534\u001B[0m, in \u001B[0;36mRepository.__init__\u001B[0;34m(self, local_dir, clone_from, repo_type, token, git_user, git_email, revision, skip_lfs_files, client)\u001B[0m\n\u001B[1;32m    531\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhuggingface_token \u001B[38;5;241m=\u001B[39m get_token()\n\u001B[1;32m    533\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m clone_from \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 534\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclone_from\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrepo_url\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclone_from\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    535\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    536\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m is_git_repo(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlocal_dir):\n",
      "File \u001B[0;32m~/PycharmProjects/MLOps/madewithml/venv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:114\u001B[0m, in \u001B[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    111\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m check_use_auth_token:\n\u001B[1;32m    112\u001B[0m     kwargs \u001B[38;5;241m=\u001B[39m smoothly_deprecate_use_auth_token(fn_name\u001B[38;5;241m=\u001B[39mfn\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m, has_token\u001B[38;5;241m=\u001B[39mhas_token, kwargs\u001B[38;5;241m=\u001B[39mkwargs)\n\u001B[0;32m--> 114\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/MLOps/madewithml/venv/lib/python3.10/site-packages/huggingface_hub/repository.py:698\u001B[0m, in \u001B[0;36mRepository.clone_from\u001B[0;34m(self, repo_url, token)\u001B[0m\n\u001B[1;32m    695\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    696\u001B[0m     \u001B[38;5;66;03m# Check if the folder is the root of a git repository\u001B[39;00m\n\u001B[1;32m    697\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_git_repo(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlocal_dir):\n\u001B[0;32m--> 698\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mEnvironmentError\u001B[39;00m(\n\u001B[1;32m    699\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTried to clone a repository in a non-empty folder that isn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    700\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m a git repository (\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlocal_dir\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m). If you really want to\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    701\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m do this, do it manually:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m cd \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlocal_dir\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m && git init\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    702\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m && git remote add origin && git pull origin main\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m or clone\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    703\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m repo to a new folder and move your existing files there\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    704\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m afterwards.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    705\u001B[0m         )\n\u001B[1;32m    707\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m is_local_clone(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlocal_dir, repo_url):\n\u001B[1;32m    708\u001B[0m         logger\u001B[38;5;241m.\u001B[39mwarning(\n\u001B[1;32m    709\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlocal_dir\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m is already a clone of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mclean_repo_url\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    710\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m Make sure you pull the latest changes with\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    711\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m `repo.git_pull()`.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    712\u001B[0m         )\n",
      "\u001B[0;31mOSError\u001B[0m: Tried to clone a repository in a non-empty folder that isn't a git repository ('/Users/aswathshakthi/PycharmProjects/certified-developer/MLOps_Professional/lab9/distilbert_tuning/distilbert-emotions-clf-m1'). If you really want to do this, do it manually:\n cd /Users/aswathshakthi/PycharmProjects/certified-developer/MLOps_Professional/lab9/distilbert_tuning/distilbert-emotions-clf-m1 && git init && git remote add origin && git pull origin main\n or clone repo to a new folder and move your existing files there afterwards."
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "65bf9282-e2f0-4331-a558-7637871c5109",
   "metadata": {},
   "source": [
    "# Conclusion and Discussion\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "In this section of the workshop, we successfully uploaded a model to the Hugging Face Hub. This process included logging into Hugging Face, loading the model and tokenizer, saving them with appropriate names, and finally pushing them to the Hub. #\n",
    "\n",
    "## Discussion\n",
    "\n",
    "The ability to share models via platforms like Hugging Face Hub is invaluable in the field of AI and ML. It not only fosters collaboration and open-source contributions but also provides a platform for model evaluation and improvement by the community. Uploading models with detailed documentation and model cards ensures transparency and usability, paving the way for future advancements and applications.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
